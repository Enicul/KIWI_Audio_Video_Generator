# ü•ù KIWI-Video

**Voice-to-Video Generation Platform with Multi-Agent Architecture**

Transform your voice or text descriptions into stunning AI-generated videos using Google's Veo 2 technology. KIWI-Video features intelligent clarification dialogs and automatic multi-scene story segmentation.

![Next.js](https://img.shields.io/badge/Next.js-15.2-black)
![FastAPI](https://img.shields.io/badge/FastAPI-0.115-009688)
![Gemini](https://img.shields.io/badge/Gemini-Veo_2.0-4285F4)
![Python](https://img.shields.io/badge/Python-3.11+-3776AB)
![TypeScript](https://img.shields.io/badge/TypeScript-5.7-3178C6)

---

## ‚ú® Features

- üé§ **Voice Input** - Record audio directly in the browser
- üí¨ **Intelligent Clarification** - AI asks follow-up questions to understand your vision
- üé¨ **Multi-Scene Stories** - Automatically splits narratives into scenes
- üîó **Video Stitching** - Combines multiple scenes into one video
- ‚ö° **Real-time Progress** - WebSocket-based live status updates
- üîê **Secure Authentication** - Powered by Clerk

---

## üìÅ Project Structure

```
KIWI-Video/
‚îú‚îÄ‚îÄ backend/                    # FastAPI Backend
‚îÇ   ‚îú‚îÄ‚îÄ agents/                 # Multi-Agent Architecture
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py            # Base agent class
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ speech_agent.py    # Audio ‚Üí Text (Gemini)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ clarification_agent.py  # Intent clarification
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ intent_agent.py    # Text ‚Üí Intent analysis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ script_analyzer_agent.py # Scene segmentation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prompt_agent.py    # Intent ‚Üí Video prompt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ video_agent.py     # Prompt ‚Üí Video (Veo 2)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ video_stitch_agent.py   # Multi-video concatenation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ orchestrator.py    # Agent coordinator
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes.py          # REST API endpoints
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ websocket.py       # WebSocket handlers
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py         # Pydantic models
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ conversation_manager.py  # Conversation state
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gemini_service.py  # Gemini API wrapper
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ task_manager.py    # Async task management
‚îÇ   ‚îú‚îÄ‚îÄ generated/videos/      # Output video files
‚îÇ   ‚îú‚îÄ‚îÄ main.py                # Application entry point
‚îÇ   ‚îú‚îÄ‚îÄ config.py              # Configuration settings
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt       # Python dependencies
‚îÇ
‚îú‚îÄ‚îÄ front/                      # Next.js Frontend
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx     # Root layout with Clerk
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx       # Landing page
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dashboard/     # Main application
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sign-in/       # Clerk sign-in
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sign-up/       # Clerk sign-up
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ middleware.ts      # Auth middleware
‚îÇ   ‚îú‚îÄ‚îÄ tailwind.config.ts     # Tailwind CSS config
‚îÇ   ‚îî‚îÄ‚îÄ package.json           # Node dependencies
‚îÇ
‚îî‚îÄ‚îÄ README.md                   # This file
```

---

## üèóÔ∏è Architecture

### Multi-Agent System

KIWI-Video uses a **Multi-Agent Architecture** where specialized agents collaborate to transform voice/text input into video:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         ORCHESTRATOR                                 ‚îÇ
‚îÇ                    (Coordinates all agents)                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                         ‚îÇ                         ‚îÇ
        ‚ñº                         ‚ñº                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  SpeechAgent  ‚îÇ       ‚îÇ  IntentAgent    ‚îÇ       ‚îÇ ScriptAnalyzer  ‚îÇ
‚îÇ  Audio ‚Üí Text ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Text ‚Üí Intent  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Scene Detection ‚îÇ
‚îÇ   (Gemini)    ‚îÇ       ‚îÇ    (Gemini)     ‚îÇ       ‚îÇ    (Gemini)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                           ‚îÇ
                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                              ‚îÇ                            ‚îÇ
                              ‚ñº                            ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  PromptAgent    ‚îÇ          ‚îÇ  PromptAgent    ‚îÇ
                    ‚îÇ  Scene 1 Prompt ‚îÇ          ‚îÇ  Scene N Prompt ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ                            ‚îÇ
                              ‚ñº                            ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   VideoAgent    ‚îÇ          ‚îÇ   VideoAgent    ‚îÇ
                    ‚îÇ   Veo 2 Gen     ‚îÇ          ‚îÇ   Veo 2 Gen     ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ                            ‚îÇ
                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                           ‚îÇ
                                           ‚ñº
                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                              ‚îÇ   VideoStitchAgent      ‚îÇ
                              ‚îÇ   Concatenate Videos    ‚îÇ
                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Agent Descriptions

| Agent | Purpose | Technology |
|-------|---------|------------|
| **SpeechAgent** | Transcribes audio to text | Gemini 2.5 Flash |
| **ClarificationAgent** | Asks follow-up questions for unclear requests | Gemini 2.5 Flash |
| **IntentAgent** | Extracts structured intent (topic, style, mood) | Gemini 2.5 Flash |
| **ScriptAnalyzerAgent** | Detects multi-scene narratives and segments | Gemini 2.5 Flash |
| **PromptAgent** | Generates optimized video prompts | Gemini 2.5 Flash |
| **VideoAgent** | Creates videos from prompts | Veo 2.0 |
| **VideoStitchAgent** | Concatenates multiple video clips | MoviePy |
| **Orchestrator** | Coordinates the entire pipeline | Custom |

### Data Flow

```
User Input (Voice/Text)
         ‚îÇ
         ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Frontend‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ POST /api/video ‚îÇ
    ‚îÇ (React) ‚îÇ      ‚îÇ   /create       ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                    ‚îÇ
         ‚îÇ WebSocket          ‚ñº
         ‚îÇ /ws/{task_id}  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ Backend ‚îÇ
         ‚îÇ                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                     ‚îÇ
         ‚ñº                     ‚ñº
    Real-time          Agent Pipeline
    Progress           (Multi-Agent)
    Updates                   ‚îÇ
         ‚îÇ                    ‚ñº
         ‚îÇ            Generated Video
         ‚îÇ                    ‚îÇ
         ‚ñº                    ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Display ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ GET /api/video  ‚îÇ
    ‚îÇ  Video  ‚îÇ      ‚îÇ   /file/{id}    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üöÄ Installation

### Prerequisites

- **Python 3.11+** (recommended: 3.13)
- **Node.js 18+** (recommended: 20 LTS)
- **npm** or **yarn**
- **Google Gemini API Key** (with Veo 2 access)
- **Clerk Account** (for authentication)

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/KIWI-Video.git
cd KIWI-Video
```

### 2. Backend Setup

```bash
# Navigate to backend
cd backend

# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
.\venv\Scripts\activate   # Windows

# Install dependencies
pip install -r requirements.txt

# Create environment file
cp env.example .env

# Edit .env and add your API key
# GEMINI_API_KEY=your_gemini_api_key_here
```

### 3. Frontend Setup

```bash
# Navigate to frontend
cd ../front

# Install dependencies
npm install

# Create environment file
cp env.example .env.local

# Edit .env.local and add Clerk keys
# NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=pk_test_xxx
# CLERK_SECRET_KEY=sk_test_xxx
```

### 4. Configure API Keys

**Backend `.env`:**
```env
GEMINI_API_KEY=your_gemini_api_key
DEBUG=true
API_HOST=0.0.0.0
API_PORT=8000
```

**Frontend `.env.local`:**
```env
NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=pk_test_xxx
CLERK_SECRET_KEY=sk_test_xxx
NEXT_PUBLIC_CLERK_SIGN_IN_URL=/sign-in
NEXT_PUBLIC_CLERK_SIGN_UP_URL=/sign-up
NEXT_PUBLIC_CLERK_AFTER_SIGN_IN_URL=/dashboard
NEXT_PUBLIC_CLERK_AFTER_SIGN_UP_URL=/dashboard
```

---

## ‚ñ∂Ô∏è Running the Application

### Start Backend Server

```bash
cd backend
source venv/bin/activate  # If using virtual environment
python main.py
```

The backend will start at `http://localhost:8000`

- API Docs: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

### Start Frontend Server

```bash
cd front
npm run dev
```

The frontend will start at `http://localhost:3000`

### Both Running Together

You need **two terminal windows**:

**Terminal 1 (Backend):**
```bash
cd backend && python main.py
```

**Terminal 2 (Frontend):**
```bash
cd front && npm run dev
```

---

## üìñ Usage Guide

### 1. Sign In

Navigate to `http://localhost:3000` and sign in with your Clerk account.

### 2. Dashboard

After signing in, you'll be redirected to the dashboard with two modes:

#### Mode 1: Direct Generation

1. Click the **microphone button** and describe your video
2. Or type your description in the text input
3. Click **"Generate Directly"** to skip the conversation
4. Wait for video generation (typically 30-60 seconds per scene)
5. Watch your generated video!

#### Mode 2: AI Discussion (Recommended)

1. Describe your initial idea via voice or text
2. Click **"Discuss with AI"**
3. Answer the AI's clarification questions
4. Once satisfied, click **"Generate Video"**
5. The AI will create a more refined video based on your conversation

### 3. Multi-Scene Stories

For complex narratives, KIWI-Video automatically:

1. Detects if your description contains multiple scenes
2. Segments the story (e.g., "wake up, drink coffee, go to work" ‚Üí 3 scenes)
3. Generates each scene separately
4. Stitches all scenes into one final video

**Example:**
```
"A person wakes up in the morning, stretches, goes to the kitchen 
 to make coffee, and then walks out the door to go to work"
```
‚Üí Automatically creates 3 separate video clips and combines them

---

## üîå API Reference

### REST Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/video/create` | Create video generation task |
| `GET` | `/api/task/{task_id}` | Get task status |
| `GET` | `/api/video/file/{filename}` | Download generated video |
| `POST` | `/api/conversation/message` | Send conversation message |
| `POST` | `/api/conversation/{id}/generate` | Generate from conversation |

### WebSocket

Connect to `/ws/{task_id}` for real-time updates:

```javascript
const ws = new WebSocket(`ws://localhost:8000/ws/${taskId}`);

ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  console.log(data.phase, data.progress, data.message);
  // { phase: "execution", progress: 75, message: "Generating video..." }
};
```

---

## üõ†Ô∏è Development

### Backend Development

```bash
cd backend
pip install -r requirements.txt
python main.py  # Auto-reload enabled
```

### Frontend Development

```bash
cd front
npm run dev     # Hot reload enabled
```

### Adding New Agents

1. Create a new file in `backend/agents/`
2. Extend `BaseAgent` class
3. Implement `process()` method
4. Register in `orchestrator.py`
5. Export in `agents/__init__.py`

```python
from .base import BaseAgent

class MyNewAgent(BaseAgent):
    def __init__(self):
        super().__init__(
            name="MyNewAgent",
            description="Does something amazing"
        )
    
    async def process(self, input_data):
        # Your logic here
        return {"success": True, "result": ...}

my_new_agent = MyNewAgent()
```

---

## üîß Configuration

### Backend Config (`config.py`)

| Variable | Default | Description |
|----------|---------|-------------|
| `API_HOST` | `0.0.0.0` | Server host |
| `API_PORT` | `8000` | Server port |
| `DEBUG` | `true` | Debug mode with auto-reload |
| `GEMINI_API_KEY` | - | Google Gemini API key |

### Frontend Environment

| Variable | Description |
|----------|-------------|
| `NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY` | Clerk publishable key |
| `CLERK_SECRET_KEY` | Clerk secret key |

---

## üì¶ Tech Stack

### Backend
- **FastAPI** - High-performance async web framework
- **Uvicorn** - ASGI server
- **Pydantic** - Data validation
- **google-genai** - Gemini & Veo 2 SDK
- **MoviePy** - Video processing
- **WebSockets** - Real-time communication

### Frontend
- **Next.js 15** - React framework (App Router)
- **React 19** - UI library
- **TypeScript** - Type safety
- **Tailwind CSS** - Utility-first styling
- **Clerk** - Authentication

---

## ‚ö†Ô∏è Known Limitations

1. **Veo 2 Access** - Requires Google AI Studio Veo 2 access (not available in all regions)
2. **Video Duration** - Maximum 8 seconds per scene
3. **Generation Time** - Each scene takes 30-60 seconds to generate
4. **API Quotas** - Subject to Gemini API rate limits

---

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üôè Acknowledgments

- [Google Gemini](https://ai.google.dev/) - AI models and Veo video generation
- [Clerk](https://clerk.com/) - Authentication
- [Next.js](https://nextjs.org/) - React framework
- [FastAPI](https://fastapi.tiangolo.com/) - Python web framework

---

<p align="center">
  Made with üíö by the KIWI-Video Team
</p>

