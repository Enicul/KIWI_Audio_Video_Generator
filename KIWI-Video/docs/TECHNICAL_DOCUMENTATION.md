# KIWI-Video æŠ€æœ¯æ–‡æ¡£

## ğŸ“‹ ç›®å½•

1. [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
2. [ç³»ç»Ÿæ¶æ„](#ç³»ç»Ÿæ¶æ„)
3. [æŠ€æœ¯æ ˆ](#æŠ€æœ¯æ ˆ)
4. [æ ¸å¿ƒæ¨¡å—è¯¦è§£](#æ ¸å¿ƒæ¨¡å—è¯¦è§£)
5. [å·¥ä½œæµç¨‹è¯¦è§£](#å·¥ä½œæµç¨‹è¯¦è§£)
6. [æ™ºèƒ½ä½“(Agent)ç³»ç»Ÿ](#æ™ºèƒ½ä½“agentç³»ç»Ÿ)
7. [æœåŠ¡æä¾›è€…(Providers)](#æœåŠ¡æä¾›è€…providers)
8. [APIæ¥å£](#apiæ¥å£)
9. [æ•°æ®æµä¸çŠ¶æ€ç®¡ç†](#æ•°æ®æµä¸çŠ¶æ€ç®¡ç†)
10. [æ–‡ä»¶ç»“æ„ä¸è¾“å‡º](#æ–‡ä»¶ç»“æ„ä¸è¾“å‡º)
11. [é…ç½®ä¸ç¯å¢ƒ](#é…ç½®ä¸ç¯å¢ƒ)
12. [æ‰©å±•å¼€å‘æŒ‡å—](#æ‰©å±•å¼€å‘æŒ‡å—)

---

## é¡¹ç›®æ¦‚è¿°

**KIWI-Video** æ˜¯ä¸€ä¸ªç”Ÿäº§çº§çš„ã€åŸºäºå¤šæ™ºèƒ½ä½“æ¶æ„çš„æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆæ¡†æ¶ã€‚å®ƒèƒ½å¤Ÿå°†ç”¨æˆ·çš„æ–‡æœ¬æè¿°è‡ªåŠ¨è½¬æ¢ä¸ºä¸“ä¸šè´¨é‡çš„è§†é¢‘å†…å®¹ã€‚

### æ ¸å¿ƒç‰¹æ€§

- âœ¨ **å¤šæ™ºèƒ½ä½“åä½œæ¶æ„** - æ¯ä¸ªåˆ¶ä½œé˜¶æ®µç”±ä¸“é—¨çš„AIæ™ºèƒ½ä½“è´Ÿè´£
- ğŸ¬ **éŸ³é¢‘ä¼˜å…ˆå·¥ä½œæµ** - å…ˆç”ŸæˆéŸ³é¢‘ç¡®å®šæ—¶é•¿ï¼Œå†æ®æ­¤è¿›è¡Œç²¾ç¡®çš„è§†é¢‘è§„åˆ’
- ğŸ¤– **Google Veoé›†æˆ** - ä½¿ç”¨æœ€å…ˆè¿›çš„AIè§†é¢‘ç”ŸæˆæŠ€æœ¯
- ğŸ§  **Gemini LLM** - æ™ºèƒ½å†³ç­–å’Œå†…å®¹ç”Ÿæˆ
- ğŸ™ï¸ **ElevenLabs TTS** - é«˜è´¨é‡çš„è¯­éŸ³åˆæˆå’ŒASR
- ğŸ”„ **å®Œå…¨å¼‚æ­¥** - é«˜æ€§èƒ½çš„å¼‚æ­¥æ“ä½œ
- ğŸ“¦ **ç±»å‹å®‰å…¨** - ä½¿ç”¨Pydanticè¿›è¡Œå®Œæ•´çš„ç±»å‹æ³¨è§£
- ğŸ› ï¸ **æ˜“äºæ‰©å±•** - ç®€å•æ·»åŠ æ–°çš„æä¾›è€…å’Œæ™ºèƒ½ä½“

### åº”ç”¨åœºæ™¯

- æ•™è‚²è§†é¢‘è‡ªåŠ¨ç”Ÿæˆ
- è¥é”€å†…å®¹å¿«é€Ÿåˆ¶ä½œ
- æ–°é—»æ‘˜è¦è§†é¢‘åŒ–
- æ•…äº‹è®²è¿°å¯è§†åŒ–
- äº§å“æ¼”ç¤ºè§†é¢‘

---

## ç³»ç»Ÿæ¶æ„

### æ€»ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ç”¨æˆ·è¾“å…¥                               â”‚
â”‚              "åˆ›å»ºä¸€ä¸ªå…³äºæœªæ¥æ–°åŠ å¡çš„45ç§’è§†é¢‘"               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Director Orchestrator                       â”‚
â”‚                    (å¯¼æ¼”ç¼–æ’å™¨)                              â”‚
â”‚        ç»Ÿç­¹ç®¡ç†æ•´ä¸ªè§†é¢‘ç”Ÿæˆæµç¨‹                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚         â”‚          â”‚           â”‚
        â–¼         â–¼          â–¼           â–¼
    â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Storyâ”‚  â”‚Voice   â”‚ â”‚Storyboardâ”‚ â”‚FilmCrew  â”‚
    â”‚Loaderâ”‚ â”‚Actor   â”‚ â”‚Agent     â”‚ â”‚Agent     â”‚
    â”‚Agent â”‚ â”‚Agent   â”‚ â”‚æ™ºèƒ½ä½“    â”‚ â”‚æ™ºèƒ½ä½“    â”‚
    â”‚æ™ºèƒ½ä½“â”‚ â”‚æ™ºèƒ½ä½“  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚         â”‚          â”‚           â”‚
        â–¼         â–¼          â–¼           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         å¤–éƒ¨æœåŠ¡æä¾›è€…å±‚                â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  Gemini LLM  â”‚  ElevenLabs  â”‚  Veo API  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚    æœ€ç»ˆè§†é¢‘è¾“å‡º        â”‚
            â”‚    final_video.mp4     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒè®¾è®¡æ¨¡å¼

1. **ç¼–æ’è€…æ¨¡å¼(Orchestrator Pattern)** - DirectorOrchestratorç»Ÿç­¹æ‰€æœ‰æ™ºèƒ½ä½“
2. **ä»£ç†æ¨¡å¼(Agent Pattern)** - æ¯ä¸ªæ™ºèƒ½ä½“å°è£…ç‰¹å®šé¢†åŸŸçš„é€»è¾‘
3. **æä¾›è€…æ¨¡å¼(Provider Pattern)** - æŠ½è±¡å¤–éƒ¨æœåŠ¡æ¥å£
4. **çŠ¶æ€ç®¡ç†æ¨¡å¼** - é›†ä¸­å¼çŠ¶æ€æŒä¹…åŒ–å’Œæ¢å¤

---

## æŠ€æœ¯æ ˆ

### æ ¸å¿ƒæŠ€æœ¯

| æŠ€æœ¯ | ç‰ˆæœ¬ | ç”¨é€” |
|------|------|------|
| Python | 3.10+ | ä¸»ç¼–ç¨‹è¯­è¨€ |
| FastAPI | 0.109.0+ | REST APIæ¡†æ¶ |
| Pydantic | 2.5.0+ | æ•°æ®éªŒè¯å’Œåºåˆ—åŒ– |
| Google Gemini | latest | å¤§è¯­è¨€æ¨¡å‹(LLM) |
| Google Veo | latest | AIè§†é¢‘ç”Ÿæˆ |
| ElevenLabs | 1.0.0+ | è¯­éŸ³åˆæˆå’ŒASR |
| MoviePy | 1.0.3+ | è§†é¢‘å¤„ç† |
| FFmpeg | - | åº•å±‚è§†é¢‘æ“ä½œ |

### å¼€å‘å·¥å…·

- **Ruff** - ä»£ç æ ¼å¼åŒ–å’ŒLinting
- **Pytest** - æµ‹è¯•æ¡†æ¶
- **MyPy** - é™æ€ç±»å‹æ£€æŸ¥
- **Uvicorn** - ASGIæœåŠ¡å™¨
- **Loguru** - æ—¥å¿—ç®¡ç†

---

## æ ¸å¿ƒæ¨¡å—è¯¦è§£

### 1. å¯¼æ¼”ç¼–æ’å™¨ (DirectorOrchestrator)

**æ–‡ä»¶ä½ç½®**: `kiwi_video/core/orchestrator.py`

**èŒè´£**: ç»Ÿç­¹ç®¡ç†æ•´ä¸ªè§†é¢‘ç”Ÿæˆæµç¨‹ï¼Œåè°ƒå„ä¸ªæ™ºèƒ½ä½“çš„æ‰§è¡Œé¡ºåºã€‚

#### å…³é”®æ–¹æ³•

```python
async def execute_project(self, user_input: str) -> dict[str, Any]:
    """
    æ‰§è¡Œå®Œæ•´çš„è§†é¢‘ç”Ÿæˆå·¥ä½œæµ
    
    æµç¨‹:
    1. Phase 1: ç”Ÿæˆè„šæœ¬ (StoryLoader)
    2. Phase 2: ç”ŸæˆéŸ³é¢‘ (VoiceActor) - éŸ³é¢‘ä¼˜å…ˆï¼
    3. Phase 3: åˆ›å»ºåˆ†é•œ (Storyboard) - ä½¿ç”¨å®é™…éŸ³é¢‘æ—¶é•¿
    4. Phase 4: ç”Ÿæˆè§†é¢‘ç‰‡æ®µ (FilmCrew)
    5. Phase 5: åˆæˆæœ€ç»ˆè§†é¢‘
    
    è¿”å›:
        åŒ…å«æœ€ç»ˆè§†é¢‘è·¯å¾„å’Œå…ƒæ•°æ®çš„å­—å…¸
    """
```

#### å·¥ä½œæµç¨‹é¡ºåº

```python
# Phase 1: è„šæœ¬ç”Ÿæˆ
script_result = await self._run_story_loader(user_input)

# Phase 2: éŸ³é¢‘ç”Ÿæˆ (åœ¨åˆ†é•œä¹‹å‰ï¼)
audio_result = await self._run_voice_actor(script_result)

# Phase 3: åˆ†é•œåˆ›å»º (ä½¿ç”¨å®é™…éŸ³é¢‘æ—¶é•¿)
storyboard_result = await self._run_storyboard(script_result, audio_result)

# Phase 4: è§†é¢‘ç‰‡æ®µç”Ÿæˆ
clips_results = await self._run_film_crew(storyboard_result, audio_result)

# Phase 5: æœ€ç»ˆåˆæˆ
final_video = await self._compile_final_video(clips_results)
```

#### éŸ³é¢‘ä¼˜å…ˆçš„ä¼˜åŠ¿

ä¼ ç»Ÿæµç¨‹çš„é—®é¢˜:
```
è„šæœ¬ â†’ åˆ†é•œ(ä¼°ç®—æ—¶é•¿) â†’ è§†é¢‘ç”Ÿæˆ â†’ éŸ³é¢‘ç”Ÿæˆ â†’ âŒ æ—¶é•¿ä¸åŒ¹é…
```

KIWI-Videoçš„éŸ³é¢‘ä¼˜å…ˆæµç¨‹:
```
è„šæœ¬ â†’ éŸ³é¢‘ç”Ÿæˆ(è·å–ç²¾ç¡®æ—¶é•¿) â†’ åˆ†é•œ(ä½¿ç”¨å®é™…æ—¶é•¿) â†’ è§†é¢‘ç”Ÿæˆ â†’ âœ… å®Œç¾åŒæ­¥
```

### 2. åŸºç¡€æ™ºèƒ½ä½“ (BaseAgent)

**æ–‡ä»¶ä½ç½®**: `kiwi_video/core/base_agent.py`

**èŒè´£**: æ‰€æœ‰æ™ºèƒ½ä½“çš„æŠ½è±¡åŸºç±»ï¼Œæä¾›é€šç”¨åŠŸèƒ½ã€‚

#### æ ¸å¿ƒç»„ä»¶

```python
class BaseAgent(ABC):
    """æ‰€æœ‰æ™ºèƒ½ä½“çš„åŸºç±»"""
    
    def __init__(
        self,
        agent_name: str,           # æ™ºèƒ½ä½“åç§°
        llm_client: BaseLLMClient, # LLMå®¢æˆ·ç«¯
        state_manager: StateManager,# çŠ¶æ€ç®¡ç†å™¨
        workspace_dir: Path        # å·¥ä½œç›®å½•
    ):
        self.conversation_history = []  # å¯¹è¯å†å²
        self.tools = self.register_tools()  # æ³¨å†Œå·¥å…·
```

#### å¿…é¡»å®ç°çš„æŠ½è±¡æ–¹æ³•

```python
@abstractmethod
def register_tools(self) -> dict[str, Callable]:
    """æ³¨å†Œæ™ºèƒ½ä½“ä¸“ç”¨å·¥å…·"""
    pass

@abstractmethod
def get_system_prompt(self) -> str:
    """è¿”å›ç³»ç»Ÿæç¤ºè¯"""
    pass

@abstractmethod
def _execute_workflow(self, input_data: dict) -> dict:
    """æ‰§è¡Œæ™ºèƒ½ä½“ç‰¹å®šçš„å·¥ä½œæµé€»è¾‘"""
    pass
```

#### æ™ºèƒ½ä½“å¾ªç¯ (Agent Loop)

```python
def agent_loop(
    self,
    objective: str,           # ç›®æ ‡ä»»åŠ¡
    goal_check: Callable,     # ç›®æ ‡æ£€æŸ¥å‡½æ•°
    max_turns: int = 50       # æœ€å¤§è½®æ¬¡
) -> bool:
    """
    æ‰§è¡Œæ™ºèƒ½ä½“å¾ªç¯ç›´åˆ°ç›®æ ‡è¾¾æˆ
    
    å¾ªç¯æµç¨‹:
    1. æ£€æŸ¥ç›®æ ‡æ˜¯å¦è¾¾æˆ
    2. è°ƒç”¨LLMè·å–å†³ç­–
    3. æ‰§è¡Œå·¥å…·è°ƒç”¨
    4. æ›´æ–°å¯¹è¯å†å²
    5. é‡å¤ç›´åˆ°å®Œæˆæˆ–è¾¾åˆ°æœ€å¤§è½®æ¬¡
    """
```

### 3. çŠ¶æ€ç®¡ç†å™¨ (StateManager)

**æ–‡ä»¶ä½ç½®**: `kiwi_video/core/state_manager.py`

**èŒè´£**: ç®¡ç†é¡¹ç›®çŠ¶æ€çš„æŒä¹…åŒ–å’Œæ¢å¤ã€‚

#### çŠ¶æ€ç»“æ„

```json
{
  "project_id": "test_20251211_203720",
  "status": "processing",
  "user_input": "åˆ›å»ºè§†é¢‘...",
  "created_at": "2024-12-11T20:37:20",
  "updated_at": "2024-12-11T20:45:33",
  "current_phase": "film_crew",
  "phases": {
    "story_loader": {
      "status": "completed",
      "started_at": "2024-12-11T20:37:21",
      "completed_at": "2024-12-11T20:38:05",
      "result": {...}
    },
    "voice_actor": {...},
    "storyboard": {...},
    "film_crew": {...}
  },
  "scenes": {
    "scene_001": {
      "audio_path": "audio/scene_001_voice.mp3",
      "audio_duration": 8.5,
      "asr_path": "audio/scene_001_asr.json",
      "clip_path": "clips/scene_001_clip.mp4"
    }
  },
  "final_output": {
    "final_video_path": "final_video.mp4"
  }
}
```

#### å…³é”®æ–¹æ³•

```python
class StateManager:
    def update_state(self, updates: dict) -> None:
        """æ›´æ–°çŠ¶æ€"""
        
    def start_phase(self, phase_name: str) -> None:
        """å¼€å§‹ä¸€ä¸ªæ–°é˜¶æ®µ"""
        
    def complete_phase(self, phase_name: str, result: dict) -> None:
        """å®Œæˆä¸€ä¸ªé˜¶æ®µ"""
        
    def update_scene_state(self, scene_id: str, scene_data: dict) -> None:
        """æ›´æ–°åœºæ™¯çŠ¶æ€"""
        
    def get_state(self) -> dict:
        """è·å–å½“å‰çŠ¶æ€"""
```

---

## å·¥ä½œæµç¨‹è¯¦è§£

### å®Œæ•´æµç¨‹æ—¶åºå›¾

```
ç”¨æˆ·      Orchestrator   StoryLoader   VoiceActor   Storyboard   FilmCrew   VideoProcessor
 â”‚             â”‚              â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚â”€è¾“å…¥æ–‡æœ¬â”€â†’â”‚              â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚             â”‚              â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚             â”‚â”€Phase 1â”€â”€â”€â”€â†’â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚             â”‚              â”‚â”€ç”Ÿæˆè„šæœ¬   â”‚            â”‚           â”‚            â”‚
 â”‚             â”‚              â”‚â”€ä¿å­˜JSON   â”‚            â”‚           â”‚            â”‚
 â”‚             â”‚â†â”€è„šæœ¬æ•°æ®â”€â”€â”€â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚             â”‚              â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚             â”‚â”€Phase 2â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚            â”‚           â”‚            â”‚
 â”‚             â”‚              â”‚             â”‚â”€åˆæˆè¯­éŸ³   â”‚           â”‚            â”‚
 â”‚             â”‚              â”‚             â”‚â”€è·å–æ—¶é•¿   â”‚           â”‚            â”‚
 â”‚             â”‚              â”‚             â”‚â”€ç”ŸæˆASR    â”‚           â”‚            â”‚
 â”‚             â”‚â†â”€éŸ³é¢‘å…ƒæ•°æ®â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚            â”‚           â”‚            â”‚
 â”‚             â”‚              â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚             â”‚â”€Phase 3â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚           â”‚            â”‚
 â”‚             â”‚              â”‚             â”‚            â”‚â”€åˆ›å»ºåˆ†é•œ â”‚            â”‚
 â”‚             â”‚              â”‚             â”‚            â”‚(ä½¿ç”¨å®é™…æ—¶é•¿)         â”‚
 â”‚             â”‚â†â”€åˆ†é•œæ•°æ®â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚           â”‚            â”‚
 â”‚             â”‚              â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚             â”‚â”€Phase 4â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚            â”‚
 â”‚             â”‚              â”‚             â”‚            â”‚           â”‚â”€ç”Ÿæˆè§†é¢‘ â”‚
 â”‚             â”‚              â”‚             â”‚            â”‚           â”‚â”€è°ƒæ•´æ—¶é•¿ â”‚
 â”‚             â”‚              â”‚             â”‚            â”‚           â”‚â”€åˆæˆéŸ³é¢‘ â”‚
 â”‚             â”‚â†â”€è§†é¢‘ç‰‡æ®µâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚            â”‚
 â”‚             â”‚              â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚             â”‚â”€Phase 5â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚
 â”‚             â”‚              â”‚             â”‚            â”‚           â”‚            â”‚â”€æ‹¼æ¥è§†é¢‘
 â”‚             â”‚â†â”€æœ€ç»ˆè§†é¢‘â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
 â”‚             â”‚              â”‚             â”‚            â”‚           â”‚            â”‚
 â”‚â†æœ€ç»ˆç»“æœâ”€â”€â”€â”‚              â”‚             â”‚            â”‚           â”‚            â”‚
```

### Phase 1: è„šæœ¬ç”Ÿæˆ (StoryLoader Agent)

#### è¾“å…¥
```python
{
    "topic": "åˆ›å»ºä¸€ä¸ªå…³äºæœªæ¥æ–°åŠ å¡çš„è§†é¢‘",
    "style": "professional"
}
```

#### å¤„ç†æµç¨‹

1. **åŠ è½½æç¤ºæ¨¡æ¿**
```python
# ä» config/prompts/story_loader.txt åŠ è½½
system_prompt = load_prompt("story_loader")
```

2. **æ„å»ºç”Ÿæˆæç¤º**
```python
generation_prompt = f"""Generate a video script for the following topic:

Topic: {topic}
Style: {style}

Create 5 scenes that tell a compelling story.
Output ONLY valid JSON with this EXACT structure:

{{
  "topic": "{topic}",
  "style": "{style}",
  "total_duration": <30-90 seconds>,
  "scenes": [
    {{
      "scene_id": "scene_001",
      "scene_description": "è§†è§‰æè¿°",
      "voice_over_text": "æ—ç™½æ–‡æœ¬",
      "duration": 8.0,
      "mood": "engaging",
      "visual_style": "professional"
    }}
  ]
}}
"""
```

3. **è°ƒç”¨LLMç”Ÿæˆ**
```python
response = self.llm_client.stream(
    prompt=generation_prompt,
    purpose="script_generation"
)
```

4. **è§£æå’ŒéªŒè¯**
```python
script_data = self._parse_llm_response(response)
# éªŒè¯å¿…éœ€å­—æ®µ: topic, style, scenes
# éªŒè¯æ¯ä¸ªscene: scene_id, scene_description, voice_over_text
```

5. **ä¿å­˜è¾“å‡º**
```python
# ä¿å­˜è„šæœ¬: annotated_script.json
# ä¿å­˜é£æ ¼æŒ‡å—: style_guide.txt
```

#### è¾“å‡ºç¤ºä¾‹

```json
{
  "topic": "åˆ›å»ºä¸€ä¸ªå…³äºæœªæ¥æ–°åŠ å¡çš„è§†é¢‘",
  "style": "professional",
  "total_duration": 45,
  "scenes": [
    {
      "scene_id": "scene_001",
      "scene_description": "æœªæ¥æ–°åŠ å¡çš„å¤©é™…çº¿ï¼Œæ‘©å¤©å¤§æ¥¼é—´ç©¿æ¢­ç€é£è¡Œæ±½è½¦",
      "voice_over_text": "æ¬¢è¿æ¥åˆ°2050å¹´çš„æ–°åŠ å¡ï¼Œä¸€ä¸ªç§‘æŠ€ä¸è‡ªç„¶å’Œè°å…±å­˜çš„åŸå¸‚",
      "duration": 9.0,
      "mood": "inspiring",
      "visual_style": "professional"
    },
    {
      "scene_id": "scene_002",
      "scene_description": "å‚ç›´å†œåœºå†…éƒ¨ï¼Œç»¿è‰²æ¤ç‰©å±‚å±‚å å ",
      "voice_over_text": "åŸå¸‚ä¸­çš„å‚ç›´å†œåœºä¸ºå±…æ°‘æä¾›æ–°é²œçš„é£Ÿç‰©ï¼Œå®ç°äº†ç²®é£Ÿè‡ªç»™è‡ªè¶³",
      "duration": 10.0,
      "mood": "hopeful",
      "visual_style": "professional"
    }
    // ... æ›´å¤šåœºæ™¯
  ]
}
```

### Phase 2: éŸ³é¢‘ç”Ÿæˆ (VoiceActor Agent)

**å…³é”®åˆ›æ–°**: åœ¨åˆ†é•œåˆ¶ä½œä¹‹å‰ç”ŸæˆéŸ³é¢‘ï¼Œè·å–ç²¾ç¡®æ—¶é•¿ï¼

#### è¾“å…¥
```python
{
    "scenes": [
        {
            "scene_id": "scene_001",
            "voice_over_text": "æ¬¢è¿æ¥åˆ°2050å¹´çš„æ–°åŠ å¡...",
            "duration": 9.0  # è¿™æ˜¯ä¼°ç®—å€¼ï¼Œä¼šè¢«å®é™…éŸ³é¢‘æ—¶é•¿æ›¿æ¢
        }
    ]
}
```

#### å¤„ç†æµç¨‹

1. **éå†æ‰€æœ‰åœºæ™¯**
```python
for scene in scenes:
    scene_id = scene["scene_id"]
    voice_text = scene["voice_over_text"]
    
    # ç”ŸæˆéŸ³é¢‘å’ŒASR
    metadata = await self._generate_scene_audio(scene_id, voice_text)
```

2. **è¯­éŸ³åˆæˆ**
```python
# ä½¿ç”¨ElevenLabsåˆæˆè¯­éŸ³
await self.voice_client.synthesize(
    text=voice_text,
    voice_id=voice_id,  # å¯é€‰ï¼Œä½¿ç”¨é»˜è®¤å£°éŸ³
    output_path=audio_path  # audio/scene_001_voice.mp3
)
```

3. **è·å–éŸ³é¢‘æ—¶é•¿**
```python
# ä½¿ç”¨mutagenåº“è¯»å–MP3å…ƒæ•°æ®
audio = MP3(str(audio_path))
duration = audio.info.length  # å®é™…æ—¶é•¿ï¼Œä¾‹å¦‚ 8.47 ç§’
```

4. **ç”ŸæˆASR(è‡ªåŠ¨è¯­éŸ³è¯†åˆ«)**
```python
# ä½¿ç”¨ElevenLabsçš„speech-to-textè·å–è¯çº§æ—¶é—´æˆ³
asr_data = await self.voice_client.speech_to_text(
    audio_path=audio_path,
    output_path=asr_path  # audio/scene_001_asr.json
)
```

#### ASRæ•°æ®ç»“æ„

```json
{
  "text": "æ¬¢è¿æ¥åˆ°2050å¹´çš„æ–°åŠ å¡ï¼Œä¸€ä¸ªç§‘æŠ€ä¸è‡ªç„¶å’Œè°å…±å­˜çš„åŸå¸‚",
  "duration": 8.47,
  "words": [
    {
      "word": "æ¬¢è¿",
      "start": 0.0,
      "end": 0.45,
      "confidence": 0.98
    },
    {
      "word": "æ¥åˆ°",
      "start": 0.45,
      "end": 0.89,
      "confidence": 0.97
    }
    // ... æ›´å¤šå•è¯æ—¶é—´æˆ³
  ]
}
```

#### è¾“å‡º

```python
{
    "scenes_processed": 5,
    "scenes_metadata": {
        "scene_001": {
            "scene_id": "scene_001",
            "audio_path": "audio/scene_001_voice.mp3",
            "asr_path": "audio/scene_001_asr.json",
            "duration": 8.47,  # âœ… å®é™…éŸ³é¢‘æ—¶é•¿ï¼
            "text_length": 45,
            "word_count": 12
        }
        // ... æ›´å¤šåœºæ™¯
    }
}
```

### Phase 3: åˆ†é•œåˆ›å»º (Storyboard Agent)

#### è¾“å…¥
```python
{
    "script": {
        "scenes": [...]
    },
    "audio_metadata": {  # âœ… æ¥è‡ªPhase 2çš„å®é™…éŸ³é¢‘æ•°æ®
        "scene_001": {
            "duration": 8.47,  # å®é™…æ—¶é•¿
            "audio_path": "...",
            "asr_path": "..."
        }
    }
}
```

#### å¤„ç†æµç¨‹

1. **æ›¿æ¢ä¼°ç®—æ—¶é•¿ä¸ºå®é™…æ—¶é•¿**
```python
for scene in scenes:
    scene_id = scene['scene_id']
    
    # å¦‚æœæœ‰éŸ³é¢‘å…ƒæ•°æ®ï¼Œä½¿ç”¨å®é™…æ—¶é•¿
    if scene_id in audio_metadata:
        actual_duration = audio_metadata[scene_id]['duration']
        scene['duration'] = actual_duration  # æ›¿æ¢ä¼°ç®—å€¼
        
        logger.info(
            f"ä½¿ç”¨å®é™…éŸ³é¢‘æ—¶é•¿: {actual_duration:.2f}s "
            f"(ä¼°ç®—: {scene.get('duration', 0)}s)"
        )
```

2. **ä¸ºæ¯ä¸ªåœºæ™¯è§„åˆ’é•œå¤´**
```python
shots = self._plan_shots_with_llm(scene)
```

3. **LLMé•œå¤´è§„åˆ’æç¤º**
```python
planning_prompt = f"""Plan detailed shots for this scene:

Scene ID: {scene['scene_id']}
Description: {scene['scene_description']}
Voice-over: {scene['voice_over_text']}
Duration: {scene_duration} seconds (actual audio duration)

IMPORTANT: The total duration of all shots MUST equal {scene_duration} seconds exactly.
This is the actual recorded voice-over duration, so shots must be precisely timed.

Create 1-3 shots that effectively tell this scene's story.
Output valid JSON array of shots:

[
  {{
    "shot_id": "scene_001_shot_001",
    "shot_description": "Opening establishing shot",
    "visual_description": "Detailed visual description",
    "duration": 3.5,
    "timing": {{
      "start_time": 0.0,
      "end_time": 3.5
    }},
    "visuals": {{
      "composition": {{
        "shot_type": "wide",
        "camera_angle": "high-angle",
        "camera_movement": "drone flyover"
      }},
      "lighting": "golden hour",
      "mood": "inspiring"
    }},
    "voice_over_cue": "æ¬¢è¿æ¥åˆ°2050å¹´çš„æ–°åŠ å¡"
  }}
]
"""
```

4. **è§„èŒƒåŒ–é•œå¤´ID**
```python
def _normalize_shot_ids(shots, scene_id):
    """
    ç¡®ä¿é•œå¤´IDæ ¼å¼ç»Ÿä¸€: scene_XXX_shot_YYY
    """
    for idx, shot in enumerate(shots, start=1):
        standard_id = f"{scene_id}_shot_{idx:03d}"
        shot["shot_id"] = standard_id
```

#### è¾“å‡ºç¤ºä¾‹

```json
{
  "storyboard_id": "storyboard_20251211_203720",
  "created_at": "2024-12-11T20:37:25",
  "scenes": [
    {
      "scene_id": "scene_001",
      "scene_description": "æœªæ¥æ–°åŠ å¡çš„å¤©é™…çº¿...",
      "voice_over_text": "æ¬¢è¿æ¥åˆ°2050å¹´çš„æ–°åŠ å¡...",
      "duration": 8.47,  # âœ… å®é™…éŸ³é¢‘æ—¶é•¿
      "shots": [
        {
          "shot_id": "scene_001_shot_001",
          "visual_description": "ä»é«˜å¤„ä¿¯ç°æ–°åŠ å¡å¤©é™…çº¿ï¼Œæ‘©å¤©å¤§æ¥¼é—´é£è¡Œæ±½è½¦ç©¿æ¢­",
          "duration": 4.0,
          "timing": {
            "start_time": 0.0,
            "end_time": 4.0
          },
          "visuals": {
            "composition": {
              "shot_type": "wide",
              "camera_angle": "high-angle",
              "camera_movement": "slow drone descent"
            },
            "lighting": "golden hour",
            "mood": "inspiring",
            "color_palette": "warm tones"
          },
          "voice_over_cue": "æ¬¢è¿æ¥åˆ°2050å¹´çš„æ–°åŠ å¡"
        },
        {
          "shot_id": "scene_001_shot_002",
          "visual_description": "ç‰¹å†™é•œå¤´ï¼šé£è¡Œæ±½è½¦åœ¨æ‘©å¤©å¤§æ¥¼é—´ç©¿æ¢­",
          "duration": 4.47,
          "timing": {
            "start_time": 4.0,
            "end_time": 8.47
          },
          "visuals": {
            "composition": {
              "shot_type": "medium",
              "camera_angle": "eye-level",
              "camera_movement": "tracking shot"
            },
            "lighting": "bright daylight",
            "mood": "dynamic"
          },
          "voice_over_cue": "ä¸€ä¸ªç§‘æŠ€ä¸è‡ªç„¶å’Œè°å…±å­˜çš„åŸå¸‚"
        }
      ]
    }
  ]
}
```

### Phase 4: è§†é¢‘åˆ¶ä½œ (FilmCrew Agent)

#### è¾“å…¥
```python
{
    "scene": {
        "scene_id": "scene_001",
        "shots": [...]  # æ¥è‡ªåˆ†é•œ
    },
    "audio_metadata": {
        "duration": 8.47,
        "audio_path": "audio/scene_001_voice.mp3",
        "asr_path": "audio/scene_001_asr.json"
    }
}
```

#### å¤„ç†æµç¨‹

**Step 1: ç”Ÿæˆåˆ¶ä½œè®¡åˆ’**

```python
def _generate_high_level_plan(scene, audio_duration, asr_path):
    """
    ä¼˜å…ˆä½¿ç”¨åˆ†é•œæ¿çš„é•œå¤´è®¡åˆ’
    """
    storyboard_shots = scene.get('shots', [])
    
    if storyboard_shots:
        # âœ… ç›´æ¥ä½¿ç”¨åˆ†é•œæ¿çš„é•œå¤´
        plan_data = {
            "scene_id": scene['scene_id'],
            "total_duration": audio_duration,  # ä½¿ç”¨å®é™…éŸ³é¢‘æ—¶é•¿
            "shots": storyboard_shots,
            "composition_strategy": "Follow storyboard shot sequence"
        }
    else:
        # åå¤‡ï¼šç”¨LLMç”Ÿæˆè®¡åˆ’
        plan_data = self._generate_plan_with_llm(scene, audio_duration)
    
    return plan_data
```

**Step 2: ä¸ºæ¯ä¸ªé•œå¤´ç”Ÿæˆè§†é¢‘ç´ æ**

```python
for shot in plan['shots']:
    # æ„å»ºVeoæç¤ºè¯
    veo_prompt = self._build_veo_prompt(shot)
    
    # è°ƒç”¨Veoç”Ÿæˆè§†é¢‘
    video_path = await self.veo_client.generate_and_download(
        prompt=veo_prompt["veo_prompt"],
        negative_prompt=veo_prompt["negative_prompt"],
        duration=int(shot['duration']),  # Veoéœ€è¦æ•´æ•°ç§’
        output_path=output_path
    )
```

**Veoæç¤ºè¯æ„å»º**

```python
def _build_veo_prompt(shot):
    """
    ä»åˆ†é•œæ•°æ®æ„å»ºVeoç”Ÿæˆæç¤º
    """
    visual_desc = shot['visual_description']
    
    # æå–ç›¸æœºå‚æ•°
    camera_movement = shot['visuals']['composition']['camera_movement']
    camera_angle = shot['visuals']['composition']['camera_angle']
    shot_type = shot['visuals']['composition']['shot_type']
    
    # æ„å»ºå®Œæ•´æç¤º
    veo_prompt = f"{visual_desc}, "
    veo_prompt += f"camera: {camera_movement} {camera_angle} {shot_type}, "
    veo_prompt += f"lighting: {shot['visuals']['lighting']}, "
    veo_prompt += f"mood: {shot['visuals']['mood']}, "
    veo_prompt += "cinematic quality, professional production, smooth camera work"
    
    # è´Ÿé¢æç¤º
    negative_prompt = (
        "blurry, low quality, amateur, shaky camera, poorly lit, "
        "pixelated, distorted, text overlay, subtitles, watermarks"
    )
    
    return {
        "veo_prompt": veo_prompt,
        "negative_prompt": negative_prompt
    }
```

**Step 3: è°ƒæ•´è§†é¢‘æ—¶é•¿**

Veoç”Ÿæˆçš„è§†é¢‘å¯èƒ½ä¸æ˜¯ç²¾ç¡®çš„ç›®æ ‡æ—¶é•¿ï¼Œéœ€è¦è°ƒæ•´ï¼š

```python
for shot, asset_path in shot_assets:
    target_duration = shot['duration']  # ä¾‹å¦‚ 4.47ç§’
    
    # ä½¿ç”¨VideoProcessorè°ƒæ•´æ—¶é•¿
    await VideoProcessor.adjust_video_duration(
        input_path=asset_path,
        target_duration=target_duration,
        output_path=adjusted_path
    )
```

**Step 4: æ‹¼æ¥é•œå¤´**

å¦‚æœåœºæ™¯æœ‰å¤šä¸ªé•œå¤´ï¼š

```python
if len(adjusted_videos) > 1:
    await VideoProcessor.concat_videos(
        video_paths=adjusted_videos,
        output_path=concatenated_path
    )
```

**Step 5: åˆå¹¶éŸ³é¢‘**

```python
await VideoProcessor.merge_video_audio(
    video_path=base_video,
    audio_path=voice_path,  # é¢„ç”Ÿæˆçš„éŸ³é¢‘
    text=voice_text,  # å¯é€‰ï¼šç”Ÿæˆå­—å¹•
    output_path=clip_path  # clips/scene_001_clip.mp4
)
```

#### è¾“å‡º

```python
{
    "scene_id": "scene_001",
    "clip_path": "clips/scene_001_clip.mp4",
    "assets_created": 2,  # ç”Ÿæˆäº†2ä¸ªé•œå¤´
    "audio_path": "audio/scene_001_voice.mp3",
    "audio_duration": 8.47
}
```

### Phase 5: æœ€ç»ˆåˆæˆ

#### å¤„ç†æµç¨‹

```python
async def _compile_final_video(clips_results):
    """
    å°†æ‰€æœ‰åœºæ™¯ç‰‡æ®µæ‹¼æ¥æˆæœ€ç»ˆè§†é¢‘
    """
    # æå–æ‰€æœ‰ç‰‡æ®µè·¯å¾„
    clip_paths = [
        Path(result["clip_path"])
        for result in clips_results
        if result.get("clip_path")
    ]
    
    # æŒ‰é¡ºåºæ‹¼æ¥
    final_video_path = workspace_dir / "final_video.mp4"
    
    await VideoProcessor.concat_videos(
        video_paths=clip_paths,
        output_path=final_video_path
    )
    
    return final_video_path
```

#### è¾“å‡º

```
workspaces/test_20251211_203720/final_video.mp4
```

æ€»æ—¶é•¿ = æ‰€æœ‰åœºæ™¯éŸ³é¢‘æ—¶é•¿ä¹‹å’Œ = å®Œç¾åŒæ­¥ï¼âœ…

---

## æ™ºèƒ½ä½“(Agent)ç³»ç»Ÿ

### Agentæ¶æ„è®¾è®¡

æ‰€æœ‰æ™ºèƒ½ä½“ç»§æ‰¿è‡ª `BaseAgent`ï¼Œå®ç°ç»Ÿä¸€æ¥å£ï¼š

```python
class CustomAgent(BaseAgent):
    def register_tools(self) -> dict[str, Callable]:
        """æ³¨å†Œå·¥å…·"""
        return {
            "tool_name": self._tool_function
        }
    
    def get_system_prompt(self) -> str:
        """è¿”å›ç³»ç»Ÿæç¤ºè¯"""
        return "You are a ..."
    
    def _execute_workflow(self, input_data: dict) -> dict:
        """æ‰§è¡Œå·¥ä½œæµ"""
        # å®ç°å…·ä½“é€»è¾‘
        return result
```

### StoryLoader Agent

**èŒè´£**: å°†ç”¨æˆ·è¾“å…¥è½¬æ¢ä¸ºç»“æ„åŒ–è„šæœ¬

**å…³é”®ä»£ç ä½ç½®**: `kiwi_video/agents/story_loader.py`

#### å·¥å…·é›†

| å·¥å…·å | åŠŸèƒ½ | å®ç° |
|--------|------|------|
| `write_script` | å†™å…¥è„šæœ¬åˆ°æ–‡ä»¶ | `_write_script()` |
| `validate_script` | éªŒè¯è„šæœ¬ç»“æ„ | `_validate_script()` |

#### æ ¸å¿ƒé€»è¾‘

```python
def _execute_workflow(self, input_data):
    topic = input_data['topic']
    style = input_data.get('style', 'professional')
    
    # 1. ç”¨LLMç”Ÿæˆè„šæœ¬
    script_data = self._generate_script_with_llm(topic, style)
    
    # 2. è§£æå’ŒéªŒè¯
    if not self._validate_script_structure(script_data):
        script_data = self._create_fallback_script(topic, style)
    
    # 3. ä¿å­˜æ–‡ä»¶
    script_path = self._save_script(script_data)
    style_guide_path = self._save_style_guide(topic, style)
    
    return {
        "script_path": str(script_path),
        "scenes": script_data["scenes"],
        "scenes_count": len(script_data["scenes"])
    }
```

#### è„šæœ¬éªŒè¯è§„åˆ™

```python
def _validate_script_structure(script_data):
    """éªŒè¯è„šæœ¬å¿…é¡»åŒ…å«"""
    required_fields = ["topic", "style", "scenes"]
    
    # éªŒè¯é¡¶å±‚å­—æ®µ
    for field in required_fields:
        if field not in script_data:
            return False
    
    # éªŒè¯åœºæ™¯æ•°ç»„
    if not isinstance(script_data["scenes"], list):
        return False
    
    # éªŒè¯æ¯ä¸ªåœºæ™¯
    for scene in script_data["scenes"]:
        required_scene_fields = [
            "scene_id",
            "scene_description",
            "voice_over_text"
        ]
        for field in required_scene_fields:
            if field not in scene:
                return False
    
    return True
```

### VoiceActor Agent

**èŒè´£**: ä¸ºæ‰€æœ‰åœºæ™¯ç”Ÿæˆé«˜è´¨é‡è¯­éŸ³å’ŒASRæ•°æ®

**å…³é”®ä»£ç ä½ç½®**: `kiwi_video/agents/voice_actor.py`

#### å·¥å…·é›†

| å·¥å…·å | åŠŸèƒ½ | å®ç° |
|--------|------|------|
| `synthesize_voice` | åˆæˆè¯­éŸ³ | `_synthesize_voice_tool()` |
| `list_voices` | åˆ—å‡ºå¯ç”¨å£°éŸ³ | `_list_voices_tool()` |

#### æ ¸å¿ƒé€»è¾‘

```python
async def _execute_workflow(self, input_data):
    scenes = input_data['scenes']
    scenes_metadata = {}
    
    # ä¸ºæ¯ä¸ªåœºæ™¯ç”ŸæˆéŸ³é¢‘
    for scene_data in scenes:
        scene_id = scene_data['scene_id']
        voice_text = scene_data['voice_over_text']
        
        # ç”ŸæˆéŸ³é¢‘ + ASR
        metadata = await self._generate_scene_audio(
            scene_id=scene_id,
            voice_text=voice_text,
            generate_asr=True
        )
        
        scenes_metadata[scene_id] = metadata
    
    return {
        "scenes_processed": len(scenes_metadata),
        "scenes_metadata": scenes_metadata
    }
```

#### éŸ³é¢‘ç”Ÿæˆè¯¦ç»†æ­¥éª¤

```python
async def _generate_scene_audio(scene_id, voice_text):
    audio_path = workspace / "audio" / f"{scene_id}_voice.mp3"
    asr_path = workspace / "audio" / f"{scene_id}_asr.json"
    
    # Step 1: åˆæˆè¯­éŸ³
    await voice_client.synthesize(
        text=voice_text,
        voice_id=voice_id,  # å¯æŒ‡å®šç‰¹å®šå£°éŸ³
        output_path=audio_path
    )
    
    # Step 2: è·å–æ—¶é•¿
    audio = MP3(str(audio_path))
    duration = audio.info.length
    
    # Step 3: ç”ŸæˆASR
    asr_data = await voice_client.speech_to_text(
        audio_path=audio_path,
        output_path=asr_path
    )
    
    return {
        "scene_id": scene_id,
        "audio_path": str(audio_path),
        "asr_path": str(asr_path),
        "duration": duration,
        "asr_data": asr_data
    }
```

### Storyboard Agent

**èŒè´£**: åˆ›å»ºè¯¦ç»†çš„é•œå¤´çº§åˆ†é•œ

**å…³é”®ä»£ç ä½ç½®**: `kiwi_video/agents/storyboard.py`

#### æ ¸å¿ƒé€»è¾‘

```python
def _execute_workflow(self, input_data):
    script_data = input_data['script']
    audio_metadata = input_data.get('audio_metadata', {})
    scenes = script_data['scenes']
    
    storyboard_scenes = []
    
    for scene in scenes:
        scene_id = scene['scene_id']
        
        # âœ… ä½¿ç”¨å®é™…éŸ³é¢‘æ—¶é•¿
        if scene_id in audio_metadata:
            actual_duration = audio_metadata[scene_id]['duration']
            scene['duration'] = actual_duration
        
        # ä¸ºåœºæ™¯è§„åˆ’é•œå¤´
        scene_with_shots = self._create_shot_breakdown(scene)
        storyboard_scenes.append(scene_with_shots)
    
    # ä¿å­˜åˆ†é•œ
    storyboard_data = {
        "storyboard_id": f"storyboard_{timestamp}",
        "scenes": storyboard_scenes
    }
    
    storyboard_path = self._save_storyboard(storyboard_data)
    
    return {
        "storyboard_path": str(storyboard_path),
        "scenes": storyboard_scenes,
        "total_shots": sum(len(s['shots']) for s in storyboard_scenes)
    }
```

#### é•œå¤´è§„åˆ’ç­–ç•¥

```python
def _create_shot_breakdown(scene):
    """
    ä¸ºå•ä¸ªåœºæ™¯åˆ›å»ºé•œå¤´åˆ†è§£
    """
    # ä½¿ç”¨LLMè§„åˆ’é•œå¤´
    shots = self._plan_shots_with_llm(scene)
    
    if not shots:
        # åå¤‡ï¼šåˆ›å»ºå•é•œå¤´
        shots = self._create_default_shots(scene)
    
    # è§„èŒƒåŒ–é•œå¤´ID
    shots = self._normalize_shot_ids(shots, scene['scene_id'])
    
    scene['shots'] = shots
    scene['total_duration'] = scene['duration']
    
    return scene
```

### FilmCrew Agent

**èŒè´£**: ç”Ÿæˆè§†é¢‘ç´ æå¹¶åˆæˆåœºæ™¯ç‰‡æ®µ

**å…³é”®ä»£ç ä½ç½®**: `kiwi_video/agents/film_crew.py`

#### ä¾èµ–æœåŠ¡

- **VeoClient**: Google Veo AIè§†é¢‘ç”Ÿæˆ
- **ElevenLabsClient**: è¯­éŸ³æœåŠ¡ï¼ˆå¦‚éœ€é‡æ–°ç”Ÿæˆï¼‰
- **VideoProcessor**: è§†é¢‘å¤„ç†å·¥å…·

#### æ ¸å¿ƒé€»è¾‘

```python
async def _execute_workflow(self, input_data):
    scene = input_data['scene']
    audio_metadata = input_data['audio_metadata']
    scene_id = scene['scene_id']
    
    audio_duration = audio_metadata['duration']
    audio_path = Path(audio_metadata['audio_path'])
    asr_path = audio_metadata.get('asr_path')
    
    # Step 1: ç”Ÿæˆåˆ¶ä½œè®¡åˆ’ï¼ˆä½¿ç”¨åˆ†é•œçš„é•œå¤´ï¼‰
    plan = self._generate_high_level_plan(scene, audio_duration, asr_path)
    
    # Step 2: ä¸ºæ¯ä¸ªé•œå¤´ç”Ÿæˆè§†é¢‘ç´ æ
    shot_assets = []
    for shot in plan['shots']:
        asset_path = await self._create_video_asset(shot, scene_id)
        if asset_path:
            shot_assets.append((shot, asset_path))
    
    # Step 3: åˆæˆæœ€ç»ˆç‰‡æ®µï¼ˆè°ƒæ•´æ—¶é•¿ + æ‹¼æ¥ + éŸ³é¢‘ï¼‰
    final_clip = await self._compose_scene_clip(
        scene_id=scene_id,
        shot_assets=shot_assets,
        voice_path=audio_path,
        voice_text=scene['voice_over_text']
    )
    
    return {
        "scene_id": scene_id,
        "clip_path": str(final_clip),
        "assets_created": len(shot_assets),
        "audio_duration": audio_duration
    }
```

#### è§†é¢‘åˆæˆè¯¦ç»†æµç¨‹

```python
async def _compose_scene_clip(
    scene_id,
    shot_assets,  # [(shot_data, video_path), ...]
    voice_path,
    voice_text
):
    """
    åˆæˆåœºæ™¯æœ€ç»ˆç‰‡æ®µ
    """
    clip_path = workspace / "clips" / f"{scene_id}_clip.mp4"
    
    # Step 1: è°ƒæ•´æ¯ä¸ªé•œå¤´çš„æ—¶é•¿
    adjusted_videos = []
    for shot, asset_path in shot_assets:
        target_duration = shot['duration']
        adjusted_path = temp_dir / f"{shot['shot_id']}_adjusted.mp4"
        
        await VideoProcessor.adjust_video_duration(
            input_path=asset_path,
            target_duration=target_duration,
            output_path=adjusted_path
        )
        
        adjusted_videos.append(adjusted_path)
    
    # Step 2: æ‹¼æ¥å¤šä¸ªé•œå¤´
    if len(adjusted_videos) > 1:
        concat_path = temp_dir / f"{scene_id}_concat.mp4"
        await VideoProcessor.concat_videos(adjusted_videos, concat_path)
        base_video = concat_path
    else:
        base_video = adjusted_videos[0]
    
    # Step 3: åˆå¹¶éŸ³é¢‘
    await VideoProcessor.merge_video_audio(
        video_path=base_video,
        audio_path=voice_path,
        text=voice_text,  # å¯é€‰ï¼šç”Ÿæˆå­—å¹•
        output_path=clip_path
    )
    
    return clip_path
```

---

## æœåŠ¡æä¾›è€…(Providers)

### Provideræ¶æ„

æ‰€æœ‰å¤–éƒ¨æœåŠ¡é€šè¿‡Provideræ¨¡å¼æŠ½è±¡ï¼Œä¾¿äºæ›¿æ¢å’Œæµ‹è¯•ã€‚

```
providers/
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ base.py              # BaseLLMClientæŠ½è±¡ç±»
â”‚   â””â”€â”€ gemini_client.py     # Geminiå®ç°
â”œâ”€â”€ video/
â”‚   â”œâ”€â”€ base.py              # BaseVideoClientæŠ½è±¡ç±»
â”‚   â””â”€â”€ veo_client.py        # Veoå®ç°
â””â”€â”€ voice/
    â”œâ”€â”€ base.py              # BaseVoiceClientæŠ½è±¡ç±»
    â””â”€â”€ elevenlabs_client.py # ElevenLabså®ç°
```

### LLM Provider: Gemini

**æ–‡ä»¶ä½ç½®**: `kiwi_video/providers/llm/gemini_client.py`

#### æ ¸å¿ƒåŠŸèƒ½

```python
class GeminiClient(BaseLLMClient):
    """Google Gemini LLMå®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: str, model_name: str = "gemini-2.0-flash"):
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(model_name)
    
    def stream(self, prompt: str, purpose: str = "") -> str:
        """
        æµå¼ç”Ÿæˆæ–‡æœ¬
        
        Args:
            prompt: æç¤ºè¯
            purpose: ç”¨é€”æ ‡è¯†ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        
        Returns:
            ç”Ÿæˆçš„æ–‡æœ¬
        """
        response = self.model.generate_content(
            prompt,
            generation_config={
                "temperature": 0.7,
                "top_p": 0.95,
                "max_output_tokens": 8192,
            }
        )
        
        return response.text
    
    def generate_with_tools(
        self,
        messages: list[dict],
        tools: list[dict]
    ) -> dict:
        """
        å¸¦å·¥å…·è°ƒç”¨çš„ç”Ÿæˆï¼ˆç”¨äºAgent Loopï¼‰
        
        Args:
            messages: å¯¹è¯å†å²
            tools: å¯ç”¨å·¥å…·åˆ—è¡¨
        
        Returns:
            åŒ…å«æ–‡æœ¬å’Œå·¥å…·è°ƒç”¨çš„å“åº”
        """
        # å®ç°å·¥å…·è°ƒç”¨é€»è¾‘
        pass
```

#### ä½¿ç”¨ç¤ºä¾‹

```python
llm = GeminiClient(api_key=settings.gemini_api_key)

response = llm.stream(
    prompt="Generate a video script about AI",
    purpose="script_generation"
)
```

### Video Provider: Veo

**æ–‡ä»¶ä½ç½®**: `kiwi_video/providers/video/veo_client.py`

#### æ ¸å¿ƒåŠŸèƒ½

```python
class VeoClient(BaseVideoClient):
    """Google Veo AIè§†é¢‘ç”Ÿæˆå®¢æˆ·ç«¯"""
    
    def __init__(self):
        self.project_id = settings.gcp_project_id
        self.location = "us-central1"
        self.client = aiplatform.gapic.PredictionServiceClient()
    
    async def generate(
        self,
        prompt: str,
        negative_prompt: str | None = None,
        duration: int = 8,
        aspect_ratio: str = "16:9"
    ) -> str:
        """
        ç”Ÿæˆè§†é¢‘å¹¶è¿”å›GCS URI
        
        Args:
            prompt: è§†é¢‘æè¿°
            negative_prompt: è´Ÿé¢æç¤º
            duration: æ—¶é•¿ï¼ˆç§’ï¼‰
            aspect_ratio: å®½é«˜æ¯”
        
        Returns:
            GCS URI (gs://bucket/path/to/video.mp4)
        """
        request = {
            "prompt": prompt,
            "negative_prompt": negative_prompt,
            "duration_seconds": duration,
            "aspect_ratio": aspect_ratio
        }
        
        response = await self.client.predict(request)
        return response.gcs_uri
    
    async def download_from_gcs(
        self,
        gcs_uri: str,
        output_path: Path
    ) -> Path:
        """
        ä»GCSä¸‹è½½è§†é¢‘åˆ°æœ¬åœ°
        """
        bucket_name = gcs_uri.split('/')[2]
        blob_path = '/'.join(gcs_uri.split('/')[3:])
        
        storage_client = storage.Client()
        bucket = storage_client.bucket(bucket_name)
        blob = bucket.blob(blob_path)
        
        output_path.parent.mkdir(parents=True, exist_ok=True)
        blob.download_to_filename(str(output_path))
        
        return output_path
    
    async def generate_and_download(
        self,
        prompt: str,
        output_path: Path,
        **kwargs
    ) -> Path:
        """
        ä¾¿æ·æ–¹æ³•ï¼šç”Ÿæˆå¹¶ä¸‹è½½
        """
        gcs_uri = await self.generate(prompt, **kwargs)
        return await self.download_from_gcs(gcs_uri, output_path)
```

#### ä½¿ç”¨ç¤ºä¾‹

```python
veo = VeoClient()

video_path = await veo.generate_and_download(
    prompt="A futuristic city with flying cars, cinematic quality",
    negative_prompt="blurry, low quality",
    duration=8,
    output_path=Path("output/scene_001.mp4")
)
```

### Voice Provider: ElevenLabs

**æ–‡ä»¶ä½ç½®**: `kiwi_video/providers/voice/elevenlabs_client.py`

#### æ ¸å¿ƒåŠŸèƒ½

```python
class ElevenLabsClient(BaseVoiceClient):
    """ElevenLabsè¯­éŸ³åˆæˆå’ŒASRå®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: str | None = None):
        self.api_key = api_key or settings.elevenlabs_api_key
        self.client = ElevenLabs(api_key=self.api_key)
        self.default_voice_id = "21m00Tcm4TlvDq8ikWAM"  # Rachel
    
    async def synthesize(
        self,
        text: str,
        voice_id: str | None = None,
        output_path: Path | None = None
    ) -> bytes:
        """
        åˆæˆè¯­éŸ³
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            voice_id: å£°éŸ³IDï¼ˆå¯é€‰ï¼‰
            output_path: è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            éŸ³é¢‘äºŒè¿›åˆ¶æ•°æ®
        """
        voice_id = voice_id or self.default_voice_id
        
        audio = self.client.generate(
            text=text,
            voice=voice_id,
            model="eleven_multilingual_v2"
        )
        
        # è½¬æ¢ä¸ºbytes
        audio_bytes = b"".join(audio)
        
        if output_path:
            output_path.parent.mkdir(parents=True, exist_ok=True)
            with open(output_path, "wb") as f:
                f.write(audio_bytes)
        
        return audio_bytes
    
    async def speech_to_text(
        self,
        audio_path: Path,
        output_path: Path | None = None
    ) -> dict:
        """
        è¯­éŸ³è½¬æ–‡å­—ï¼ˆå¸¦è¯çº§æ—¶é—´æˆ³ï¼‰
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            output_path: ASRç»“æœè¾“å‡ºè·¯å¾„
        
        Returns:
            åŒ…å«æ–‡æœ¬å’Œæ—¶é—´æˆ³çš„å­—å…¸
        """
        with open(audio_path, "rb") as f:
            audio_data = f.read()
        
        # è°ƒç”¨ASR API
        result = self.client.speech_to_text(audio_data)
        
        asr_data = {
            "text": result.text,
            "words": [
                {
                    "word": word.text,
                    "start": word.start,
                    "end": word.end,
                    "confidence": word.confidence
                }
                for word in result.words
            ]
        }
        
        if output_path:
            with open(output_path, "w") as f:
                json.dump(asr_data, f, indent=2, ensure_ascii=False)
        
        return asr_data
    
    def get_voices(self) -> list[dict]:
        """è·å–å¯ç”¨å£°éŸ³åˆ—è¡¨"""
        voices = self.client.voices.get_all()
        
        return [
            {
                "voice_id": voice.voice_id,
                "name": voice.name,
                "category": voice.category
            }
            for voice in voices.voices
        ]
```

#### ä½¿ç”¨ç¤ºä¾‹

```python
voice = ElevenLabsClient()

# åˆæˆè¯­éŸ³
await voice.synthesize(
    text="Hello, this is a test",
    output_path=Path("output/test.mp3")
)

# ç”ŸæˆASR
asr_data = await voice.speech_to_text(
    audio_path=Path("output/test.mp3"),
    output_path=Path("output/test_asr.json")
)

# åˆ—å‡ºå¯ç”¨å£°éŸ³
voices = voice.get_voices()
for v in voices:
    print(f"{v['name']}: {v['voice_id']}")
```

---

## APIæ¥å£

### APIæ¶æ„

åŸºäºFastAPIæ„å»ºçš„RESTful APIï¼Œæ”¯æŒå¼‚æ­¥æ“ä½œã€‚

**ä¸»è¦æ–‡ä»¶**:
- `kiwi_video/api/app.py` - FastAPIåº”ç”¨
- `kiwi_video/api/routes/projects.py` - é¡¹ç›®è·¯ç”±
- `kiwi_video/api/routes/health.py` - å¥åº·æ£€æŸ¥

### é¡¹ç›®ç®¡ç†API

#### 1. åˆ›å»ºé¡¹ç›®

**ç«¯ç‚¹**: `POST /api/v1/projects`

**è¯·æ±‚ä½“**:
```json
{
  "prompt": "åˆ›å»ºä¸€ä¸ªå…³äºæœªæ¥æ–°åŠ å¡çš„45ç§’è§†é¢‘",
  "style": "professional",
  "duration": 45
}
```

**å“åº”**:
```json
{
  "project_id": "project_abc123",
  "status": "initialized",
  "created_at": "2024-12-11T20:37:20Z",
  "workspace_dir": "/path/to/workspaces/project_abc123"
}
```

#### 2. å¼€å§‹ç”Ÿæˆ

**ç«¯ç‚¹**: `POST /api/v1/projects/{project_id}/generate`

**å“åº”**:
```json
{
  "project_id": "project_abc123",
  "status": "processing",
  "message": "Video generation started"
}
```

åå°å¼‚æ­¥æ‰§è¡Œå·¥ä½œæµã€‚

#### 3. æŸ¥è¯¢çŠ¶æ€

**ç«¯ç‚¹**: `GET /api/v1/projects/{project_id}`

**å“åº”**:
```json
{
  "project_id": "project_abc123",
  "status": "processing",
  "current_phase": "film_crew",
  "phases": {
    "story_loader": {
      "status": "completed",
      "started_at": "2024-12-11T20:37:21Z",
      "completed_at": "2024-12-11T20:38:05Z"
    },
    "voice_actor": {
      "status": "completed",
      "started_at": "2024-12-11T20:38:06Z",
      "completed_at": "2024-12-11T20:39:15Z"
    },
    "storyboard": {
      "status": "completed",
      "started_at": "2024-12-11T20:39:16Z",
      "completed_at": "2024-12-11T20:40:30Z"
    },
    "film_crew": {
      "status": "processing",
      "started_at": "2024-12-11T20:40:31Z"
    }
  },
  "progress": 75
}
```

#### 4. è·å–ç»“æœ

**ç«¯ç‚¹**: `GET /api/v1/projects/{project_id}/result`

**å“åº”**:
```json
{
  "project_id": "project_abc123",
  "status": "completed",
  "final_video_url": "/api/v1/projects/project_abc123/video",
  "duration": 45.2,
  "scenes_count": 5,
  "created_at": "2024-12-11T20:37:20Z",
  "completed_at": "2024-12-11T20:45:33Z"
}
```

#### 5. ä¸‹è½½è§†é¢‘

**ç«¯ç‚¹**: `GET /api/v1/projects/{project_id}/video`

**å“åº”**: è§†é¢‘æ–‡ä»¶ (application/octet-stream)

### å¥åº·æ£€æŸ¥API

**ç«¯ç‚¹**: `GET /health`

**å“åº”**:
```json
{
  "status": "healthy",
  "version": "0.1.0",
  "timestamp": "2024-12-11T20:50:00Z",
  "services": {
    "gemini": "connected",
    "veo": "connected",
    "elevenlabs": "connected"
  }
}
```

### å®Œæ•´APIç¤ºä¾‹æµç¨‹

```bash
# 1. åˆ›å»ºé¡¹ç›®
curl -X POST http://localhost:8000/api/v1/projects \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "åˆ›å»ºä¸€ä¸ªå…³äºæœªæ¥æ–°åŠ å¡çš„45ç§’è§†é¢‘",
    "style": "professional"
  }'

# è¿”å›: {"project_id": "project_abc123", ...}

# 2. å¼€å§‹ç”Ÿæˆ
curl -X POST http://localhost:8000/api/v1/projects/project_abc123/generate

# 3. è½®è¯¢çŠ¶æ€ï¼ˆæ¯5ç§’ï¼‰
while true; do
  curl http://localhost:8000/api/v1/projects/project_abc123
  sleep 5
done

# 4. ä¸‹è½½è§†é¢‘ï¼ˆå½“status=completedï¼‰
curl -O http://localhost:8000/api/v1/projects/project_abc123/video
```

---

## æ•°æ®æµä¸çŠ¶æ€ç®¡ç†

### æ•°æ®æµå›¾

```
ç”¨æˆ·è¾“å…¥
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DirectorOrchestrator          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚   StateManager           â”‚  â”‚â—„â”€â”€â”€ æŒä¹…åŒ–åˆ°JSON
â”‚   â”‚   - project_state.json   â”‚  â”‚
â”‚   â”‚   - history.jsonl        â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€Phase 1: StoryLoader
    â”‚    â”œâ”€â–º annotated_script.json
    â”‚    â””â”€â–º style_guide.txt
    â”‚
    â”œâ”€Phase 2: VoiceActor
    â”‚    â”œâ”€â–º audio/scene_001_voice.mp3
    â”‚    â”œâ”€â–º audio/scene_001_asr.json
    â”‚    â”œâ”€â–º audio/scene_002_voice.mp3
    â”‚    â””â”€â–º audio/scene_002_asr.json
    â”‚
    â”œâ”€Phase 3: Storyboard
    â”‚    â”œâ”€â–º storyboard.json
    â”‚    â””â”€â–º storyboard_summary.md
    â”‚
    â”œâ”€Phase 4: FilmCrew (per scene)
    â”‚    â”œâ”€â–º assets/scene_001/scene_001_shot_001_V0.mp4
    â”‚    â”œâ”€â–º assets/scene_001/scene_001_shot_002_V0.mp4
    â”‚    â”œâ”€â–º clips/scene_001_clip.mp4
    â”‚    â””â”€â–º plans/scene_001_production_plan.json
    â”‚
    â””â”€Phase 5: VideoProcessor
         â””â”€â–º final_video.mp4
```

### çŠ¶æ€ç®¡ç†è¯¦è§£

#### StateManageræ ¸å¿ƒåŠŸèƒ½

```python
class StateManager:
    """é¡¹ç›®çŠ¶æ€ç®¡ç†å™¨"""
    
    def __init__(self, workspace_dir: Path):
        self.workspace_dir = workspace_dir
        self.state_file = workspace_dir / "project_state.json"
        self.history_file = workspace_dir / "history.jsonl"
        
        # åŠ è½½æˆ–åˆå§‹åŒ–çŠ¶æ€
        self.state = self._load_state()
    
    def update_state(self, updates: dict) -> None:
        """
        æ›´æ–°çŠ¶æ€ï¼ˆæ”¯æŒåµŒå¥—æ›´æ–°ï¼‰
        
        Example:
            update_state({
                "status": "processing",
                "scenes.scene_001.audio_path": "audio/scene_001.mp3"
            })
        """
        for key, value in updates.items():
            self._set_nested_value(self.state, key, value)
        
        self.state["updated_at"] = datetime.now().isoformat()
        self._save_state()
        self._log_to_history("update", updates)
    
    def start_phase(self, phase_name: str) -> None:
        """æ ‡è®°é˜¶æ®µå¼€å§‹"""
        self.state["phases"][phase_name] = {
            "status": "processing",
            "started_at": datetime.now().isoformat()
        }
        self.state["current_phase"] = phase_name
        self._save_state()
        self._log_to_history("phase_start", {"phase": phase_name})
    
    def complete_phase(self, phase_name: str, result: dict) -> None:
        """æ ‡è®°é˜¶æ®µå®Œæˆ"""
        self.state["phases"][phase_name].update({
            "status": "completed",
            "completed_at": datetime.now().isoformat(),
            "result": result
        })
        self._save_state()
        self._log_to_history("phase_complete", {
            "phase": phase_name,
            "result": result
        })
    
    def fail_phase(self, phase_name: str, error: str) -> None:
        """æ ‡è®°é˜¶æ®µå¤±è´¥"""
        self.state["phases"][phase_name].update({
            "status": "failed",
            "failed_at": datetime.now().isoformat(),
            "error": error
        })
        self.state["status"] = "failed"
        self._save_state()
        self._log_to_history("phase_failed", {
            "phase": phase_name,
            "error": error
        })
```

#### çŠ¶æ€æ¢å¤æœºåˆ¶

```python
def recover_project(project_id: str) -> DirectorOrchestrator:
    """
    ä»ä¸­æ–­çŠ¶æ€æ¢å¤é¡¹ç›®
    """
    workspace_dir = Path("workspaces") / project_id
    state_file = workspace_dir / "project_state.json"
    
    if not state_file.exists():
        raise ValueError(f"Project {project_id} not found")
    
    # åŠ è½½çŠ¶æ€
    with open(state_file) as f:
        state = json.load(f)
    
    # åˆ›å»ºç¼–æ’å™¨
    orchestrator = DirectorOrchestrator(
        project_id=project_id,
        workspace_dir=workspace_dir
    )
    
    # ç¡®å®šä»å“ªä¸ªé˜¶æ®µæ¢å¤
    current_phase = state.get("current_phase")
    phases = state.get("phases", {})
    
    # å¦‚æœå½“å‰é˜¶æ®µå¤±è´¥ï¼Œä»å¤±è´¥ç‚¹é‡è¯•
    if phases.get(current_phase, {}).get("status") == "failed":
        logger.info(f"Retrying failed phase: {current_phase}")
        # ... é‡è¯•é€»è¾‘
    
    return orchestrator
```

#### å†å²æ—¥å¿—æ ¼å¼ (JSONL)

```jsonl
{"timestamp": "2024-12-11T20:37:20Z", "event": "project_created", "data": {...}}
{"timestamp": "2024-12-11T20:37:21Z", "event": "phase_start", "data": {"phase": "story_loader"}}
{"timestamp": "2024-12-11T20:38:05Z", "event": "phase_complete", "data": {"phase": "story_loader", "result": {...}}}
{"timestamp": "2024-12-11T20:38:06Z", "event": "phase_start", "data": {"phase": "voice_actor"}}
...
```

---

## æ–‡ä»¶ç»“æ„ä¸è¾“å‡º

### å·¥ä½œåŒºç›®å½•ç»“æ„

æ¯ä¸ªé¡¹ç›®éƒ½æœ‰ç‹¬ç«‹çš„å·¥ä½œåŒºï¼š

```
workspaces/
â””â”€â”€ project_abc123/                    # é¡¹ç›®å·¥ä½œåŒº
    â”œâ”€â”€ project_state.json             # é¡¹ç›®çŠ¶æ€
    â”œâ”€â”€ history.jsonl                  # æ“ä½œå†å²
    â”‚
    â”œâ”€â”€ annotated_script.json          # Phase 1: è„šæœ¬
    â”œâ”€â”€ style_guide.txt                # é£æ ¼æŒ‡å—
    â”‚
    â”œâ”€â”€ audio/                         # Phase 2: éŸ³é¢‘
    â”‚   â”œâ”€â”€ scene_001_voice.mp3        #   - è¯­éŸ³æ–‡ä»¶
    â”‚   â”œâ”€â”€ scene_001_asr.json         #   - ASRæ•°æ®
    â”‚   â”œâ”€â”€ scene_002_voice.mp3
    â”‚   â””â”€â”€ scene_002_asr.json
    â”‚
    â”œâ”€â”€ storyboard.json                # Phase 3: åˆ†é•œ
    â”œâ”€â”€ storyboard_summary.md          # åˆ†é•œæ‘˜è¦
    â”‚
    â”œâ”€â”€ plans/                         # Phase 4: åˆ¶ä½œè®¡åˆ’
    â”‚   â”œâ”€â”€ scene_001_production_plan.json
    â”‚   â””â”€â”€ scene_002_production_plan.json
    â”‚
    â”œâ”€â”€ assets/                        # Phase 4: åŸå§‹è§†é¢‘ç´ æ
    â”‚   â”œâ”€â”€ scene_001/
    â”‚   â”‚   â”œâ”€â”€ scene_001_shot_001_V0.mp4
    â”‚   â”‚   â””â”€â”€ scene_001_shot_002_V0.mp4
    â”‚   â””â”€â”€ scene_002/
    â”‚       â””â”€â”€ scene_002_shot_001_V0.mp4
    â”‚
    â”œâ”€â”€ temp/                          # ä¸´æ—¶æ–‡ä»¶
    â”‚   â”œâ”€â”€ adjusted/                  #   - è°ƒæ•´æ—¶é•¿åçš„è§†é¢‘
    â”‚   â”‚   â”œâ”€â”€ scene_001_shot_001_adjusted.mp4
    â”‚   â”‚   â””â”€â”€ scene_001_shot_002_adjusted.mp4
    â”‚   â””â”€â”€ scene_001_concat.mp4       #   - æ‹¼æ¥ä¸´æ—¶æ–‡ä»¶
    â”‚
    â”œâ”€â”€ clips/                         # Phase 4: åœºæ™¯ç‰‡æ®µï¼ˆå¸¦éŸ³é¢‘ï¼‰
    â”‚   â”œâ”€â”€ scene_001_clip.mp4
    â”‚   â”œâ”€â”€ scene_002_clip.mp4
    â”‚   â””â”€â”€ scene_003_clip.mp4
    â”‚
    â””â”€â”€ final_video.mp4                # Phase 5: æœ€ç»ˆè¾“å‡º âœ…
```

### å…³é”®æ–‡ä»¶æ ¼å¼

#### annotated_script.json

```json
{
  "topic": "åˆ›å»ºä¸€ä¸ªå…³äºæœªæ¥æ–°åŠ å¡çš„45ç§’è§†é¢‘",
  "style": "professional",
  "total_duration": 45,
  "scenes": [
    {
      "scene_id": "scene_001",
      "scene_description": "æœªæ¥æ–°åŠ å¡çš„å¤©é™…çº¿ï¼Œæ‘©å¤©å¤§æ¥¼é—´ç©¿æ¢­ç€é£è¡Œæ±½è½¦",
      "voice_over_text": "æ¬¢è¿æ¥åˆ°2050å¹´çš„æ–°åŠ å¡ï¼Œä¸€ä¸ªç§‘æŠ€ä¸è‡ªç„¶å’Œè°å…±å­˜çš„åŸå¸‚",
      "duration": 9.0,
      "mood": "inspiring",
      "visual_style": "professional"
    }
  ]
}
```

#### storyboard.json

```json
{
  "storyboard_id": "storyboard_20251211_203720",
  "created_at": "2024-12-11T20:37:25Z",
  "scenes": [
    {
      "scene_id": "scene_001",
      "duration": 8.47,  // å®é™…éŸ³é¢‘æ—¶é•¿
      "shots": [
        {
          "shot_id": "scene_001_shot_001",
          "visual_description": "ä»é«˜å¤„ä¿¯ç°æ–°åŠ å¡å¤©é™…çº¿",
          "duration": 4.0,
          "timing": {
            "start_time": 0.0,
            "end_time": 4.0
          },
          "visuals": {
            "composition": {
              "shot_type": "wide",
              "camera_angle": "high-angle",
              "camera_movement": "slow drone descent"
            },
            "lighting": "golden hour",
            "mood": "inspiring"
          }
        }
      ]
    }
  ]
}
```

#### audio/scene_001_asr.json

```json
{
  "text": "æ¬¢è¿æ¥åˆ°2050å¹´çš„æ–°åŠ å¡ï¼Œä¸€ä¸ªç§‘æŠ€ä¸è‡ªç„¶å’Œè°å…±å­˜çš„åŸå¸‚",
  "duration": 8.47,
  "words": [
    {
      "word": "æ¬¢è¿",
      "start": 0.0,
      "end": 0.45,
      "confidence": 0.98
    },
    {
      "word": "æ¥åˆ°",
      "start": 0.45,
      "end": 0.89,
      "confidence": 0.97
    }
  ]
}
```

#### project_state.json

```json
{
  "project_id": "project_abc123",
  "status": "completed",
  "user_input": "åˆ›å»ºä¸€ä¸ªå…³äºæœªæ¥æ–°åŠ å¡çš„45ç§’è§†é¢‘",
  "created_at": "2024-12-11T20:37:20Z",
  "updated_at": "2024-12-11T20:45:33Z",
  "current_phase": "completed",
  "phases": {
    "story_loader": {
      "status": "completed",
      "started_at": "2024-12-11T20:37:21Z",
      "completed_at": "2024-12-11T20:38:05Z"
    },
    "voice_actor": {
      "status": "completed",
      "started_at": "2024-12-11T20:38:06Z",
      "completed_at": "2024-12-11T20:39:15Z"
    },
    "storyboard": {
      "status": "completed",
      "started_at": "2024-12-11T20:39:16Z",
      "completed_at": "2024-12-11T20:40:30Z"
    },
    "film_crew": {
      "status": "completed",
      "started_at": "2024-12-11T20:40:31Z",
      "completed_at": "2024-12-11T20:45:20Z"
    }
  },
  "scenes": {
    "scene_001": {
      "audio_path": "audio/scene_001_voice.mp3",
      "audio_duration": 8.47,
      "asr_path": "audio/scene_001_asr.json",
      "clip_path": "clips/scene_001_clip.mp4",
      "status": "completed"
    }
  },
  "final_output": {
    "final_video_path": "final_video.mp4",
    "total_duration": 45.2,
    "scenes_count": 5
  }
}
```

---

## é…ç½®ä¸ç¯å¢ƒ

### ç¯å¢ƒå˜é‡é…ç½®

**æ–‡ä»¶**: `.env`

```bash
# Google Gemini
GEMINI_API_KEY=your_gemini_api_key

# Google Cloud (for Veo)
GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json
GCP_PROJECT_ID=your-project-id
GCS_BUCKET=your-bucket-name

# ElevenLabs
ELEVENLABS_API_KEY=your_elevenlabs_api_key

# å·¥ä½œåŒºé…ç½®
WORKSPACE_DIR=./workspaces

# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO
LOG_FILE=logs/kiwi-video.log

# APIé…ç½®
API_HOST=0.0.0.0
API_PORT=8000
```

### Settingsç±»

**æ–‡ä»¶**: `kiwi_video/utils/config.py`

```python
from pydantic_settings import BaseSettings
from pathlib import Path

class Settings(BaseSettings):
    """åº”ç”¨é…ç½®"""
    
    # Google API
    gemini_api_key: str
    gcp_project_id: str
    gcs_bucket: str
    google_application_credentials: Path
    
    # ElevenLabs
    elevenlabs_api_key: str
    
    # Workspace
    workspace_dir: Path = Path("./workspaces")
    
    # Logging
    log_level: str = "INFO"
    log_file: Path | None = None
    
    # API
    api_host: str = "0.0.0.0"
    api_port: int = 8000
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"

# å…¨å±€é…ç½®å®ä¾‹
settings = Settings()
```

### ä¾èµ–ç®¡ç†

**æ–‡ä»¶**: `pyproject.toml`

```toml
[project]
name = "kiwi-video"
version = "0.1.0"
requires-python = ">=3.10"

dependencies = [
    "fastapi>=0.109.0",
    "uvicorn[standard]>=0.27.0",
    "pydantic>=2.5.0",
    "pydantic-settings>=2.1.0",
    "google-generativeai>=0.3.0",
    "google-cloud-aiplatform>=1.40.0",
    "google-cloud-storage>=2.14.0",
    "elevenlabs>=1.0.0",
    "moviepy>=1.0.3",
    "pillow>=10.2.0",
    "httpx>=0.26.0",
    "python-dotenv>=1.0.0",
    "loguru>=0.7.2",
    "mutagen>=1.47.0",  # MP3å…ƒæ•°æ®è¯»å–
]
```

### å®‰è£…æ­¥éª¤

```bash
# 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3.10 -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ– venv\Scripts\activate  # Windows

# 2. å®‰è£…ä¾èµ–
pip install -e .

# 3. å®‰è£…å¼€å‘ä¾èµ–ï¼ˆå¯é€‰ï¼‰
pip install -e ".[dev]"

# 4. é…ç½®ç¯å¢ƒå˜é‡
cp env.example .env
# ç¼–è¾‘ .env å¡«å…¥APIå¯†é’¥

# 5. éªŒè¯ç¯å¢ƒ
python check_env.py
```

---

## æ‰©å±•å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„Agent

#### æ­¥éª¤1: åˆ›å»ºAgentç±»

```python
# kiwi_video/agents/my_agent.py
from kiwi_video.core.base_agent import BaseAgent

class MyAgent(BaseAgent):
    """æˆ‘çš„è‡ªå®šä¹‰æ™ºèƒ½ä½“"""
    
    def register_tools(self) -> dict[str, Callable]:
        """æ³¨å†Œå·¥å…·"""
        return {
            "my_tool": self._my_tool
        }
    
    def get_system_prompt(self) -> str:
        """ç³»ç»Ÿæç¤ºè¯"""
        return """You are a specialized agent for..."""
    
    async def _execute_workflow(self, input_data: dict) -> dict:
        """æ‰§è¡Œå·¥ä½œæµ"""
        # å®ç°ä½ çš„é€»è¾‘
        result = {"output": "..."}
        return result
    
    def _my_tool(self, param: str) -> dict:
        """å·¥å…·å‡½æ•°"""
        return {"result": f"Processed {param}"}
```

#### æ­¥éª¤2: åœ¨Orchestratorä¸­é›†æˆ

```python
# kiwi_video/core/orchestrator.py

async def _run_my_agent(self, input_data: dict) -> dict:
    """è¿è¡Œè‡ªå®šä¹‰æ™ºèƒ½ä½“"""
    self.state_manager.start_phase("my_agent")
    
    try:
        from kiwi_video.agents.my_agent import MyAgent
        
        if self._my_agent is None:
            self._my_agent = MyAgent(
                agent_name="my_agent",
                llm_client=self.llm_client,
                state_manager=self.state_manager,
                workspace_dir=self.workspace_dir
            )
        
        result = await self._my_agent.run(input_data)
        
        self.state_manager.complete_phase("my_agent", result)
        return result
    
    except Exception as e:
        self.state_manager.fail_phase("my_agent", str(e))
        raise
```

#### æ­¥éª¤3: ä¿®æ”¹å·¥ä½œæµ

```python
async def execute_project(self, user_input: str) -> dict:
    # ... ç°æœ‰é˜¶æ®µ ...
    
    # æ·»åŠ æ–°é˜¶æ®µ
    self.logger.info("Phase X: My custom phase")
    my_result = await self._run_my_agent(previous_result)
    
    # ... ç»§ç»­åç»­é˜¶æ®µ ...
```

### æ·»åŠ æ–°çš„Provider

#### æ­¥éª¤1: å®šä¹‰åŸºç±»

```python
# kiwi_video/providers/my_service/base.py
from abc import ABC, abstractmethod

class BaseMyServiceClient(ABC):
    """æˆ‘çš„æœåŠ¡åŸºç±»"""
    
    @abstractmethod
    async def do_something(self, param: str) -> str:
        """æŠ½è±¡æ–¹æ³•"""
        pass
```

#### æ­¥éª¤2: å®ç°å…·ä½“Provider

```python
# kiwi_video/providers/my_service/my_implementation.py
from .base import BaseMyServiceClient

class MyImplementation(BaseMyServiceClient):
    """å…·ä½“å®ç°"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.client = SomeSDK(api_key=api_key)
    
    async def do_something(self, param: str) -> str:
        """å®ç°æŠ½è±¡æ–¹æ³•"""
        result = await self.client.call_api(param)
        return result
```

#### æ­¥éª¤3: åœ¨Agentä¸­ä½¿ç”¨

```python
class MyAgent(BaseAgent):
    def __init__(self, ..., my_service_client: BaseMyServiceClient):
        super().__init__(...)
        self.my_service = my_service_client
    
    async def _execute_workflow(self, input_data):
        result = await self.my_service.do_something(input_data['param'])
        return {"result": result}
```

### è‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿

#### æ­¥éª¤1: åˆ›å»ºæç¤ºè¯æ–‡ä»¶

```
config/prompts/my_agent.txt
```

```text
You are a specialized AI agent for [specific task].

Your responsibilities:
1. [Responsibility 1]
2. [Responsibility 2]

Output format:
[Expected format description]

Tools available:
- tool_1: [Description]
- tool_2: [Description]

Important guidelines:
- [Guideline 1]
- [Guideline 2]
```

#### æ­¥éª¤2: åœ¨Agentä¸­åŠ è½½

```python
from kiwi_video.utils.prompt_loader import load_prompt

class MyAgent(BaseAgent):
    def __init__(self, ...):
        super().__init__(...)
        
        # åŠ è½½æç¤ºè¯
        try:
            self._system_prompt = load_prompt("my_agent")
        except Exception:
            self._system_prompt = self._get_fallback_prompt()
    
    def get_system_prompt(self) -> str:
        return self._system_prompt
```

### æ·»åŠ æ–°çš„APIç«¯ç‚¹

```python
# kiwi_video/api/routes/my_routes.py
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel

router = APIRouter()

class MyRequest(BaseModel):
    param: str

class MyResponse(BaseModel):
    result: str

@router.post("/my-endpoint", response_model=MyResponse)
async def my_endpoint(request: MyRequest):
    """æˆ‘çš„è‡ªå®šä¹‰ç«¯ç‚¹"""
    try:
        # å¤„ç†é€»è¾‘
        result = do_something(request.param)
        return MyResponse(result=result)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

```python
# kiwi_video/api/app.py
from kiwi_video.api.routes import my_routes

app.include_router(my_routes.router, prefix="/api/v1", tags=["My Feature"])
```

---

## æ€»ç»“

### æ ¸å¿ƒä¼˜åŠ¿

1. **éŸ³é¢‘ä¼˜å…ˆæ¶æ„** â­
   - å…ˆç”ŸæˆéŸ³é¢‘è·å–ç²¾ç¡®æ—¶é•¿
   - åŸºäºå®é™…æ—¶é•¿è§„åˆ’è§†é¢‘
   - å®Œç¾çš„éŸ³è§†é¢‘åŒæ­¥

2. **æ¨¡å—åŒ–è®¾è®¡**
   - æ™ºèƒ½ä½“ç‹¬ç«‹å¯æµ‹è¯•
   - ProvideræŠ½è±¡æ˜“äºæ›¿æ¢
   - æ¸…æ™°çš„èŒè´£åˆ†ç¦»

3. **ç”Ÿäº§çº§è´¨é‡**
   - å®Œæ•´çš„é”™è¯¯å¤„ç†
   - çŠ¶æ€æŒä¹…åŒ–å’Œæ¢å¤
   - ç±»å‹å®‰å…¨å’ŒéªŒè¯

4. **æ˜“äºæ‰©å±•**
   - æ·»åŠ æ–°Agentåªéœ€ç»§æ‰¿BaseAgent
   - æ›¿æ¢Provideråªéœ€å®ç°æ¥å£
   - æç¤ºè¯å¯é…ç½®

### æŠ€æœ¯äº®ç‚¹

- ğŸ”„ **å¼‚æ­¥å·¥ä½œæµ** - é«˜æ€§èƒ½å¹¶å‘å¤„ç†
- ğŸ“Š **çŠ¶æ€ç®¡ç†** - å®Œæ•´çš„è¿›åº¦è·Ÿè¸ªå’Œæ¢å¤
- ğŸ¯ **ç²¾ç¡®åŒæ­¥** - éŸ³é¢‘ä¼˜å…ˆç¡®ä¿æ—¶é•¿åŒ¹é…
- ğŸ§© **å¤šæ™ºèƒ½ä½“åä½œ** - ä¸“ä¸šåˆ†å·¥,å„å¸å…¶èŒ
- ğŸ¨ **æ™ºèƒ½åˆ†é•œ** - LLMç”Ÿæˆä¸“ä¸šé•œå¤´è§„åˆ’
- ğŸš€ **ç”Ÿäº§å°±ç»ª** - APIã€Dockerã€æµ‹è¯•å®Œå¤‡

### æœªæ¥æ‰©å±•æ–¹å‘

1. **æ›´å¤šè§†é¢‘æ•ˆæœ**
   - è½¬åœºæ•ˆæœ
   - æ»¤é•œå’Œè°ƒè‰²
   - åŠ¨æ€å­—å¹•æ ·å¼

2. **æ™ºèƒ½ä¼˜åŒ–**
   - è‡ªåŠ¨è´¨é‡è¯„ä¼°
   - å¤šç‰ˆæœ¬ç”Ÿæˆå’Œé€‰æ‹©
   - ç”¨æˆ·åé¦ˆå­¦ä¹ 

3. **æ€§èƒ½æå‡**
   - å¹¶è¡Œåœºæ™¯ç”Ÿæˆ
   - ç¼“å­˜å¤ç”¨
   - å¢é‡æ¸²æŸ“

4. **å¤šæ¨¡æ€æ”¯æŒ**
   - å›¾ç‰‡è¾“å…¥
   - è§†é¢‘å‰ªè¾‘
   - éŸ³ä¹ç”Ÿæˆ

---

## å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£
- [Google Gemini API](https://ai.google.dev/docs)
- [Google Veo Documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/video/overview)
- [ElevenLabs API](https://elevenlabs.io/docs)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)

### é¡¹ç›®ç›¸å…³
- é¡¹ç›®ä»“åº“: [GitHub](https://github.com/your-org/kiwi-video)
- é—®é¢˜è¿½è¸ª: [Issues](https://github.com/your-org/kiwi-video/issues)
- è´¡çŒ®æŒ‡å—: [CONTRIBUTING.md](../CONTRIBUTING.md)

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0.0  
**æœ€åæ›´æ–°**: 2024-12-11  
**ç»´æŠ¤è€…**: KIWI-Video Team

